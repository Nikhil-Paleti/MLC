{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9282774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv2d(image, kernel, stride=1, padding=0):\n",
    "    # Ensure numpy arrays\n",
    "    image = np.array(image)\n",
    "    kernel = np.array(kernel)\n",
    "    \n",
    "    H, W = image.shape\n",
    "    kH, kW = kernel.shape\n",
    "    \n",
    "    # Pad image\n",
    "    if padding > 0:\n",
    "        image_padded = np.pad(image, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    else:\n",
    "        image_padded = image\n",
    "    \n",
    "    out_H = (H + 2*padding - kH)//stride + 1\n",
    "    out_W = (W + 2*padding - kW)//stride + 1\n",
    "    output = np.zeros((out_H, out_W))\n",
    "    \n",
    "    # Flip kernel (for convolution)\n",
    "    kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    # Perform convolution\n",
    "    for i in range(out_H):\n",
    "        for j in range(out_W):\n",
    "            region = image_padded[i*stride : i*stride+kH, j*stride : j*stride+kW]\n",
    "            output[i, j] = np.sum(region * kernel_flipped)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da24609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_multi_channel(image, kernels, stride=1, padding=0):\n",
    "    # image: (C_in, H, W)\n",
    "    # kernels: (C_out, C_in, kH, kW)\n",
    "    \n",
    "    C_in, H, W = image.shape\n",
    "    C_out, _, kH, kW = kernels.shape\n",
    "\n",
    "    if padding > 0:\n",
    "        image_padded = np.pad(image, ((0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    else:\n",
    "        image_padded = image\n",
    "\n",
    "    out_H = (H + 2*padding - kH)//stride + 1\n",
    "    out_W = (W + 2*padding - kW)//stride + 1\n",
    "    output = np.zeros((C_out, out_H, out_W))\n",
    "\n",
    "    # Perform convolution for each output channel\n",
    "    for co in range(C_out):\n",
    "        for ci in range(C_in):\n",
    "            kernel_flipped = np.flip(kernels[co, ci])\n",
    "            for i in range(out_H):\n",
    "                for j in range(out_W):\n",
    "                    region = image_padded[ci, i*stride : i*stride+kH, j*stride : j*stride+kW]\n",
    "                    output[co, i, j] += np.sum(region * kernel_flipped)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3433f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def conv2d_vec(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    image:  (H, W)\n",
    "    kernel: (kH, kW)  -- spatial will be flipped (true convolution)\n",
    "    returns: (out_H, out_W)\n",
    "    \"\"\"\n",
    "    image = np.asarray(image)\n",
    "    kernel = np.asarray(kernel)\n",
    "\n",
    "    kH, kW = kernel.shape\n",
    "    # pad image on spatial axes\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, ((padding, padding), (padding, padding)), mode='constant')\n",
    "\n",
    "    H, W = image.shape\n",
    "    out_H = (H - kH) // stride + 1\n",
    "    out_W = (W - kW) // stride + 1\n",
    "\n",
    "    # extract all kH×kW patches (OH, OW, kH, kW)\n",
    "    windows = sliding_window_view(image, (kH, kW))[::stride, ::stride]\n",
    "\n",
    "    # flip kernel for convolution (vs cross-correlation)\n",
    "    kflipped = kernel[::-1, ::-1]\n",
    "\n",
    "    # einsum over the last two dims (kH, kW)\n",
    "    # windows: (OH, OW, kH, kW); kflipped: (kH, kW) -> (OH, OW)\n",
    "    out = np.einsum('ijpq,pq->ij', windows, kflipped)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617b658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_multi_vec(image, kernels, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    image:   (C_in, H, W)\n",
    "    kernels: (C_out, C_in, kH, kW)\n",
    "    returns: (C_out, out_H, out_W)\n",
    "    \"\"\"\n",
    "    image = np.asarray(image)\n",
    "    kernels = np.asarray(kernels)\n",
    "\n",
    "    C_in, H, W = image.shape\n",
    "    C_out, Cin_k, kH, kW = kernels.shape\n",
    "    assert Cin_k == C_in, \"kernels second dim must equal image channels\"\n",
    "\n",
    "    # pad spatial dims only\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, ((0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "        H, W = image.shape[1:]\n",
    "\n",
    "    out_H = (H - kH) // stride + 1\n",
    "    out_W = (W - kW) // stride + 1\n",
    "\n",
    "    # sliding windows over spatial axes (H,W), per channel\n",
    "    # windows shape: (C_in, out_H, out_W, kH, kW) after striding\n",
    "    windows = sliding_window_view(image, (kH, kW), axis=(1,2))  # -> (C_in, H-kH+1, W-kW+1, kH, kW)\n",
    "    windows = windows[:, ::stride, ::stride, :, :]              # -> (C_in, out_H, out_W, kH, kW)\n",
    "\n",
    "    # flip kernels spatially for convolution\n",
    "    kflipped = kernels[..., ::-1, ::-1]  # (C_out, C_in, kH, kW)\n",
    "\n",
    "    # Contract over (C_in, kH, kW) → result (C_out, out_H, out_W)\n",
    "    # windows indices: c,i,j,p,q ; kernels: o,c,p,q → out: o,i,j\n",
    "    out = np.einsum('cijpq,ocpq->oij', windows, kflipped)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6968064",
   "metadata": {},
   "source": [
    "# Torch and as strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef21598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv2d_single_as(image: torch.Tensor, kernel: torch.Tensor, stride=1, padding=0, flip=False):\n",
    "    \"\"\"\n",
    "    image:  (H, W)\n",
    "    kernel: (kH, kW)\n",
    "    returns: (OH, OW)\n",
    "    \"\"\"\n",
    "    assert image.dim() == 2 and kernel.dim() == 2\n",
    "    kH, kW = kernel.shape\n",
    "\n",
    "    # pad on spatial dims (left,right,top,bottom)\n",
    "    x = F.pad(image.unsqueeze(0).unsqueeze(0), (padding, padding, padding, padding)).squeeze(0).squeeze(0)\n",
    "\n",
    "    H, W = x.shape\n",
    "    OH = (H - kH) // stride + 1\n",
    "    OW = (W - kW) // stride + 1\n",
    "\n",
    "    sH, sW = x.stride()\n",
    "    # raw sliding windows (unit step)\n",
    "    win = x.as_strided(size=(H - kH + 1, W - kW + 1, kH, kW),\n",
    "                       stride=(sH, sW, sH, sW))\n",
    "    # apply stride by slicing\n",
    "    win = win[::stride, ::stride]                    # (OH, OW, kH, kW)\n",
    "\n",
    "    K = kernel.flip(0,1) if flip else kernel\n",
    "    out = torch.einsum('ijpq,pq->ij', win, K)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e85c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_multi_as(x: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor | None = None,\n",
    "                    stride=1, padding=0, flip=False):\n",
    "    \"\"\"\n",
    "    x:      (C_in, H, W)\n",
    "    weight: (C_out, C_in, kH, kW)\n",
    "    returns: (C_out, OH, OW)\n",
    "    \"\"\"\n",
    "    assert x.dim() == 3 and weight.dim() == 4\n",
    "    C_in, H0, W0 = x.shape\n",
    "    C_out, Cin_w, kH, kW = weight.shape\n",
    "    assert Cin_w == C_in\n",
    "\n",
    "    # pad spatial only\n",
    "    xp = F.pad(x.unsqueeze(0), (padding, padding, padding, padding)).squeeze(0)\n",
    "    C, H, W = xp.shape\n",
    "\n",
    "    OH = (H - kH) // stride + 1\n",
    "    OW = (W - kW) // stride + 1\n",
    "\n",
    "    sC, sH, sW = xp.stride()\n",
    "    # (C_in, H-kH+1, W-kW+1, kH, kW)\n",
    "    win = xp.as_strided(size=(C, H - kH + 1, W - kW + 1, kH, kW),\n",
    "                        stride=(sC, sH, sW, sH, sW))\n",
    "    win = win[:, ::stride, ::stride]                      # (C_in, OH, OW, kH, kW)\n",
    "\n",
    "    K = weight.flip(-2, -1) if flip else weight           # (C_out, C_in, kH, kW)\n",
    "\n",
    "    # contract over (C_in, kH, kW) → (C_out, OH, OW)\n",
    "    out = torch.einsum('cijpq,ocpq->oij', win, K)\n",
    "    if bias is not None:\n",
    "        out = out + bias.view(-1, 1, 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b10b192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 4, 19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((15,4,19)).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dfceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_batched_as(x: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor | None = None,\n",
    "                      stride=1, padding=0, flip=False):\n",
    "    \"\"\"\n",
    "    x:      (N, C_in, H, W)\n",
    "    weight: (C_out, C_in, kH, kW)\n",
    "    returns: (N, C_out, OH, OW)\n",
    "    \"\"\"\n",
    "    assert x.dim() == 4 and weight.dim() == 4\n",
    "    N, C_in, H0, W0 = x.shape\n",
    "    C_out, Cin_w, kH, kW = weight.shape\n",
    "    assert Cin_w == C_in\n",
    "\n",
    "    # pad spatial dims\n",
    "    xp = F.pad(x, (padding, padding, padding, padding))\n",
    "\n",
    "    Np, C, H, W = xp.shape\n",
    "    OH = (H - kH) // stride + 1\n",
    "    OW = (W - kW) // stride + 1\n",
    "\n",
    "    sN, sC, sH, sW = xp.stride()\n",
    "    # (N, C_in, H-kH+1, W-kW+1, kH, kW)\n",
    "    win = xp.as_strided(size=(N, C, H - kH + 1, W - kW + 1, kH, kW),\n",
    "                        stride=(sN, sC, sH, sW, sH, sW))\n",
    "    win = win[:, :, ::stride, ::stride]                   # (N, C_in, OH, OW, kH, kW)\n",
    "\n",
    "    K = weight.flip(-2, -1) if flip else weight\n",
    "\n",
    "    # contract over (C_in, kH, kW): 'ncijpq,ocpq->noij'\n",
    "    out = torch.einsum('ncijpq,ocpq->noij', win, K)\n",
    "    if bias is not None:\n",
    "        out = out + bias.view(1, -1, 1, 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12662688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
