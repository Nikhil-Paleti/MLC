{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11188ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matmul_blocked(A: np.ndarray, B: np.ndarray, BS: int = 64) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    C = A @ B with cache-friendly tiling.\n",
    "    A: (M, K), B: (K, N) -> C: (M, N)\n",
    "    BS: tile (block) size along each dimension\n",
    "    \"\"\"\n",
    "    M, K = A.shape\n",
    "    K2, N = B.shape\n",
    "    assert K == K2\n",
    "\n",
    "    # Use a reasonable dtype for accumulation (prevents precision loss if inputs are int/float16)\n",
    "    C = np.zeros((M, N), dtype=np.result_type(A, B, np.float32))\n",
    "\n",
    "    # --- Outer 2D tiling over C (i,j) tiles; inner tiling over k (the reduction dim) ---\n",
    "    for ii in range(0, M, BS):          # iterate C’s rows in blocks [ii : ii+BS)\n",
    "        i_end = min(ii + BS, M)         # handle edge tiles (when M is not multiple of BS)\n",
    "        for jj in range(0, N, BS):      # iterate C’s cols in blocks [jj : jj+BS)\n",
    "            j_end = min(jj + BS, N)\n",
    "\n",
    "            # Create a view onto the C tile we’re currently producing.\n",
    "            # Cij has shape (i_block, j_block) where i_block=i_end-ii, j_block=j_end-jj.\n",
    "            Cij = C[ii:i_end, jj:j_end]\n",
    "\n",
    "            # Sweep the reduction dimension in blocks (kk ... kk+BS).\n",
    "            # We keep the C tile \"hot\" in cache while we accumulate contributions from each A/B k-tile.\n",
    "            for kk in range(0, K, BS):\n",
    "                k_end = min(kk + BS, K)\n",
    "\n",
    "                # Aik is the tile of A that contributes to Cij for this k-block\n",
    "                # shape: (i_block, k_block)\n",
    "                Aik = A[ii:i_end, kk:k_end]\n",
    "\n",
    "                # Bkj is the tile of B that contributes to Cij for this k-block\n",
    "                # shape: (k_block, j_block)\n",
    "                Bkj = B[kk:k_end, jj:j_end]\n",
    "\n",
    "                # Micro-kernel: multiply the two small tiles and accumulate into Cij.\n",
    "                # Using @ here calls BLAS on a small problem size (fast and vectorized).\n",
    "                Cij += Aik @ Bkj\n",
    "\n",
    "            # Optional: since Cij is a view into C, writing back is not strictly necessary.\n",
    "            C[ii:i_end, jj:j_end] = Cij\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c44bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max abs diff: 4.386902e-05\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "A = np.random.randn(257, 513).astype(np.float32)\n",
    "B = np.random.randn(513, 129).astype(np.float32)\n",
    "\n",
    "C1 = A @ B\n",
    "C2 = matmul_blocked(A, B, BS=64)\n",
    "print(\"max abs diff:\", np.max(np.abs(C1 - C2)))  # ~1e-5 to 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89741ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
